import "dotenv/config";
import { Worker, Queue } from "bullmq";
import crypto from "crypto";
import { logger } from "../utils/logger.js";
import { Job } from "../models/Job.js";
import { ImportLog } from "../models/ImportLog.js";
import { connectMongo } from "../config/db.js";
import { redis } from "../config/redis.js"; // âœ… shared redis connection

// ---- INITIAL SETUP ----
await connectMongo().catch((err) => {
  console.error("âŒ MongoDB connection failed:", err.message);
  process.exit(1);
});

console.log("ðŸ”— Using Redis URL:", process.env.REDIS_URL);
console.log("âœ… MongoDB connection established for worker");
console.log("ðŸš€ Worker is starting...");

// ---- HELPERS ----
function computeHash(d) {
  const key = [d.title, d.description, d.applyUrl, d.location, d.type].join("|");
  return crypto.createHash("sha1").update(key).digest("hex");
}

const concurrency = Number(process.env.QUEUE_CONCURRENCY || 10);

// ---- WORKER DEFINITION ----
const worker = new Worker(
  "job-import-queue",
  async (job) => {
    const d = job.data;
    const { importLogId, source, externalId, ...rest } = d;

    console.log(`âš™ï¸  Processing job: [${source}] ${externalId}`);

    try {
      const hash = computeHash(rest);
      const existing = await Job.findOne({ source, externalId }).lean();

      if (!existing) {
        await Job.create({ source, externalId, hash, ...rest });
        await ImportLog.updateOne({ _id: importLogId }, { $inc: { newJobs: 1 } });
        console.log(`ðŸ†• Inserted new job â†’ ${externalId}`);
        return "inserted";
      }

      if (existing.hash !== hash) {
        await Job.updateOne({ _id: existing._id }, { $set: { hash, ...rest } });
        await ImportLog.updateOne({ _id: importLogId }, { $inc: { updatedJobs: 1 } });
        console.log(`â™»ï¸  Updated existing job â†’ ${externalId}`);
        return "updated";
      }

      console.log(`â­ï¸  No changes detected â†’ ${externalId}`);
      return "noop";
    } catch (e) {
      await ImportLog.updateOne(
        { _id: importLogId },
        {
          $inc: { failedJobs: 1 },
          $push: { failures: { externalId, reason: e?.message || "unknown" } },
        }
      );
      console.error(`âŒ Failed job â†’ ${externalId} | ${e.message}`);
      throw e;
    }
  },
  { connection: redis, concurrency }
);

// ---- WORKER EVENT LISTENERS ----
worker.on("ready", () => {
  console.log("ðŸ’¼ Worker is ready and waiting for jobs...");
});

worker.on("active", (job) => {
  console.log(`â–¶ï¸  Started job: ${job.id}`);
});

worker.on("completed", (job, result) => {
  console.log(`âœ… Completed job: ${job.id} â†’ ${result}`);
  logger.debug({ id: job.id, result }, "Job completed");
});

worker.on("failed", (job, err) => {
  console.error(`âŒ Job failed: ${job?.id} â†’ ${err?.message}`);
  logger.error({ id: job?.id, err }, "Job failed");
});

worker.on("error", (err) => {
  console.error("âš ï¸  Worker error:", err.message);
});

// ---- LIVE QUEUE MONITOR ----
const monitorQueue = new Queue("job-import-queue", { connection: redis });

setInterval(async () => {
  try {
    const counts = await monitorQueue.getJobCounts();
    console.log(
      `ðŸ“Š Queue Status â†’ waiting: ${counts.waiting || 0}, active: ${counts.active || 0}, completed: ${counts.completed || 0}, failed: ${counts.failed || 0}`
    );
  } catch (err) {
    console.error("âš ï¸  Queue monitor error:", err.message);
  }
}, 10000);

// ---- HEARTBEAT ----
setInterval(() => {
  console.log(`ðŸ’“ Worker alive @ ${new Date().toLocaleTimeString()}`);
}, 60000);

// ---- GLOBAL ERROR GUARDS ----
process.on("unhandledRejection", (reason) => {
  console.error("ðŸ’¥ Unhandled Rejection:", reason);
});
process.on("uncaughtException", (err) => {
  console.error("ðŸ’¥ Uncaught Exception:", err);
});
